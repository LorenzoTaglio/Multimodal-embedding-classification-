{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fe90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, hamming_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from skmultilearn.problem_transform import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab547d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(\"..\\\\data\\\\processed\\\\df_train.pkl\")\n",
    "df_test = pd.read_pickle(\"..\\\\data\\\\processed\\\\df_test.pkl\")\n",
    "\n",
    "text_embeddings_train = torch.load(\"..\\\\data\\\\processed\\\\rocov2_captions_embeddings_train.pt\")\n",
    "text_embeddings_test = torch.load(\"..\\\\data\\\\processed\\\\rocov2_captions_embeddings_test.pt\")\n",
    "\n",
    "image_embeddings_train = torch.load(\"..\\\\data\\\\processed\\\\rocov2_image_embeddings_train.pt\")\n",
    "image_embeddings_test = torch.load(\"..\\\\data\\\\processed\\\\rocov2_image_embeddings_test.pt\")\n",
    "\n",
    "# optiimzation for better memory management\n",
    "text_embeddings_train = text_embeddings_train.detach().cpu().numpy().astype(\"float32\")\n",
    "text_embeddings_test = text_embeddings_test.detach().cpu().numpy().astype(\"float32\")\n",
    "\n",
    "image_embeddings_train = image_embeddings_train.detach().cpu().numpy().astype(\"float32\")\n",
    "image_embeddings_test = image_embeddings_test.detach().cpu().numpy().astype(\"float32\")\n",
    "\n",
    "\n",
    "# get merged embeddings\n",
    "combined_embeddings_train = np.concatenate((text_embeddings_train, image_embeddings_train), axis=1)\n",
    "combined_embeddings_test = np.concatenate((text_embeddings_test, image_embeddings_test), axis=1)\n",
    "\n",
    "combined_embeddings_train = combined_embeddings_train.astype(\"float32\")\n",
    "combined_embeddings_test = combined_embeddings_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936832bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pca and mlb\n",
    "pca = PCA(n_components=300, random_state=42)\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d3762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize labels\n",
    "y_train = mlb.fit_transform(df_train['Semantic_vec'])\n",
    "y_test = mlb.transform(df_test['Semantic_vec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4c3cc",
   "metadata": {},
   "source": [
    "# Early-fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e922a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier Chain with XGBoost...\n",
      "Predicting...\n",
      "Early fusion results:\n",
      "Accuracy: 0.39721605809965704\n",
      "F1 Score (micro): 0.8028785711189145\n",
      "F1 Score (macro): 0.34865536549750364\n",
      "F1 Score (weighted): 0.7662468504278253\n",
      "F1 Score (samples): 0.8031263879912256\n",
      "Precision (micro): 0.8256062767475035\n",
      "Precision (macro): 0.7517065081064888\n",
      "Recall (micro): 0.7813686608725002\n",
      "Recall (macro): 0.31104936797961763\n",
      "Hamming Loss: 0.057330542666935644\n"
     ]
    }
   ],
   "source": [
    "# PCA for dimensionality reduction\n",
    "X_train = pca.fit_transform(combined_embeddings_train)\n",
    "X_test = pca.transform(combined_embeddings_test)\n",
    "\n",
    "\n",
    "base_xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=3,  \n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cc = ClassifierChain(classifier=base_xgb, require_dense=[True, True])\n",
    "\n",
    "print(\"Training Classifier Chain with XGBoost...\")\n",
    "cc.fit(X_train, y_train)\n",
    "print(\"Predicting...\")\n",
    "y_pred = cc.predict(X_test)\n",
    "\n",
    "print(\"Early fusion results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score (micro):\", f1_score(y_test, y_pred, average='micro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score (samples):\", f1_score(y_test, y_pred, average='samples'))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred, average='micro'))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred, average='micro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30673ab0",
   "metadata": {},
   "source": [
    "As we can see, the classificator gives good overral results, but macro is very low. This is due to the very imbalanced dataset. This classification can be upgraded with hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da621aa3",
   "metadata": {},
   "source": [
    "# Late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f471b9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier Chains for Late Fusion...\n",
      "Training text model...\n",
      "Training image model...\n"
     ]
    }
   ],
   "source": [
    "X_text_train = pca.fit_transform(text_embeddings_train)\n",
    "X_text_test = pca.transform(text_embeddings_test)\n",
    "\n",
    "X_image_train = pca.fit_transform(image_embeddings_train)\n",
    "X_image_test = pca.transform(image_embeddings_test)\n",
    "\n",
    "base_xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=3,  \n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cc_text = ClassifierChain(classifier=base_xgb, require_dense=[True, True])\n",
    "cc_image = ClassifierChain(classifier=base_xgb, require_dense=[True, True])\n",
    "\n",
    "print(\"Training Classifier Chains for Late Fusion...\")\n",
    "print(\"Training text model...\")\n",
    "cc_text.fit(X_text_train, y_train)\n",
    "y_text_pred = cc_text.predict_proba(X_text_test)\n",
    "\n",
    "print(\"Training image model...\")\n",
    "cc_image.fit(X_image_train, y_train)\n",
    "y_image_pred = cc_image.predict_proba(X_image_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc503f2",
   "metadata": {},
   "source": [
    "## Average fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd414a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion Results:\n",
      "Accuracy: 0.35626386927577164\n",
      "F1 Score (micro): 0.7895647659427187\n",
      "F1 Score (macro): 0.2596513395533108\n",
      "F1 Score (weighted): 0.7364824816274427\n",
      "F1 Score (samples): 0.784368476546205\n",
      "Precision (micro): 0.8101749089940513\n",
      "Precision (macro): 0.5736018816231122\n",
      "Recall (micro): 0.7699772171124799\n",
      "Recall (macro): 0.2504638873798563\n",
      "Hamming Loss: 0.06132741577567077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Multimodal embedding\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Average predictions\n",
    "y_pred_avg = (y_text_pred + y_image_pred) / 2\n",
    "y_pred_avg = (y_pred_avg >= 0.5).astype(int) # Convert probabilities to binary predictions\n",
    "\n",
    "print(\"Late Fusion Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_avg))\n",
    "print(\"F1 Score (micro):\", f1_score(y_test, y_pred_avg, average='micro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_avg, average='macro'))\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred_avg, average='weighted'))\n",
    "print(\"F1 Score (samples):\", f1_score(y_test, y_pred_avg, average='samples'))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred_avg, average='micro'))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_avg, average='macro'))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred_avg, average='micro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_avg, average='macro'))\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred_avg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be022e12",
   "metadata": {},
   "source": [
    "## Weighted average fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e16918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion Results:\n",
      "Accuracy: 0.3650393383094614\n",
      "F1 Score (micro): 0.7909075357112308\n",
      "F1 Score (macro): 0.33255306894885983\n",
      "F1 Score (weighted): 0.752012242959549\n",
      "F1 Score (samples): 0.7874766061723899\n",
      "Precision (micro): 0.801881883618073\n",
      "Precision (macro): 0.7668664985357759\n",
      "Recall (micro): 0.7802295164964982\n",
      "Recall (macro): 0.29990970378739545\n",
      "Hamming Loss: 0.0616426265886625\n"
     ]
    }
   ],
   "source": [
    "y_pred_weighted = (0.7 * y_text_pred + 0.3 * y_image_pred) / 1\n",
    "y_pred_weighted = (y_pred_weighted >= 0.5).astype(int) # Convert probabilities to binary predictions\n",
    "\n",
    "print(\"Late Fusion Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_weighted))\n",
    "print(\"F1 Score (micro):\", f1_score(y_test, y_pred_weighted, average='micro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_weighted, average='macro'))\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_pred_weighted, average='weighted'))\n",
    "print(\"F1 Score (samples):\", f1_score(y_test, y_pred_weighted, average='samples'))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_pred_weighted, average='micro'))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_weighted, average='macro'))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_pred_weighted, average='micro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_weighted, average='macro'))\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876357d1",
   "metadata": {},
   "source": [
    "## Meta-classifier fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed1b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Meta-classifier...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "preds_text_test = cc_text.predict_proba(X_text_test)\n",
    "preds_image_test = cc_image.predict_proba(X_image_test)\n",
    "train_base = np.hstack((cc_text.predict_proba(X_text_train).toarray(), cc_image.predict_proba(X_image_train).toarray()))\n",
    "test_base = np.hstack((preds_text_test.toarray(), preds_image_test.toarray()))\n",
    "\n",
    "meta_xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=3,\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "cc_meta = ClassifierChain(classifier=meta_xgb, require_dense=[True, True])\n",
    "print(\"Training Meta-classifier...\")\n",
    "cc_meta.fit(train_base, y_train)\n",
    "print(\"Predicting with Meta-classifier...\")\n",
    "y_meta_pred = cc_meta.predict(test_base)\n",
    "print(\"Meta-classifier Fusion Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_meta_pred))\n",
    "print(\"F1 Score (micro):\", f1_score(y_test, y_meta_pred, average='micro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_meta_pred,    average='macro'))\n",
    "print(\"F1 Score (weighted):\", f1_score(y_test, y_meta_pred, average='weighted'))\n",
    "print(\"F1 Score (samples):\", f1_score(y_test, y_meta_pred, average='samples'))\n",
    "print(\"Precision (micro):\", precision_score(y_test, y_meta_pred, average='micro'))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_meta_pred, average='macro'))\n",
    "print(\"Recall (micro):\", recall_score(y_test, y_meta_pred, average='micro'))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_meta_pred, average='macro'))\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_meta_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
